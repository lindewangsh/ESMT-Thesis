{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "387b077e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# importing libraries/packages needed\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "import pprint\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "bearer_token = \"BEARER_TOKEN_GOES_HERE\"\n",
    "search_url = \"https://api.twitter.com/2/tweets/search/all\"\n",
    "\n",
    "# Optional params: start_time,end_time,since_id,until_id,max_results,next_token,\n",
    "# expansions,tweet.fields,media.fields,poll.fields,place.fields,user.fields\n",
    "\n",
    "# NAME FILE HERE FIRST\n",
    "# NAME FILE HERE FIRST\n",
    "# NAME FILE HERE FIRST\n",
    "raw_data = \"bitcoin_210531.json\"\n",
    "filename = \"bitcoin_210531_final.xlsx\"\n",
    "\n",
    "# CHANGE DAYS HERE\n",
    "# CHANGE DAYS HERE\n",
    "# CHANGE DAYS HERE\n",
    "select_year = 2021\n",
    "select_month = 5\n",
    "select_day = 31\n",
    "start_hour = 0\n",
    "end_hour = 23\n",
    "\n",
    "# CHANGE KEYWORD HERE\n",
    "# CHANGE KEYWORD HERE\n",
    "# CHANGE KEYWORD HERE\n",
    "# Define global query parameters\n",
    "default_query_params = {\n",
    "    'query': 'bitcoin -is:retweet lang:en place_country:us has:geo',\n",
    "    'tweet.fields': 'created_at,author_id,text,geo',\n",
    "    'expansions': \"geo.place_id\",\n",
    "    'place.fields': \"place_type\",\n",
    "    'max_results': 500,\n",
    "    'start_time': \"\",\n",
    "    'end_time': \"\",\n",
    "}\n",
    "\n",
    "def create_headers(bearer_token):\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    return headers\n",
    "\n",
    "def connect_to_endpoint(url, headers, params):\n",
    "    response = requests.request(\"GET\", search_url, headers=headers, params=params)\n",
    "    print(response.status_code)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()\n",
    "\n",
    "def build_params(year, month, day, hour, query_params):\n",
    "    big_t = \"T\"\n",
    "    start_minute = \"00:00.000Z\"\n",
    "    end_minute = \"59:59.999Z\"\n",
    "\n",
    "    start_time = (str(hour), start_minute)\n",
    "    start_time_formatted = \":\".join(start_time)\n",
    "    full_start_time = big_t + start_time_formatted\n",
    "    start_date = (str(year), str(month), str(day))\n",
    "    start_date_formatted = \"-\".join(start_date)\n",
    "    full_start_date = start_date_formatted + full_start_time\n",
    "\n",
    "    end_time = (str(hour), end_minute)\n",
    "    end_time_formatted = \":\".join(end_time)\n",
    "    full_end_time = big_t + end_time_formatted\n",
    "    end_date = (str(year), str(month), str(day))\n",
    "    end_date_formatted = \"-\".join(end_date)\n",
    "    full_end_date = end_date_formatted + full_end_time\n",
    "\n",
    "    query_params[\"start_time\"] = full_start_date\n",
    "    query_params[\"end_time\"] = full_end_date\n",
    "    return query_params\n",
    "\n",
    "def add_region(tweetz, placeDict):\n",
    "    all_tweets = []\n",
    "    for tweet in tweetz:\n",
    "        if 'geo' in tweet:\n",
    "            place_id = tweet['geo']['place_id']\n",
    "            place = placeDict[place_id]\n",
    "\n",
    "            # parse state from place.name\n",
    "            place_type = place['place_type']\n",
    "            if place_type == 'city':            \n",
    "                # split the full name of the place by the comma\n",
    "                place_name = place['full_name']\n",
    "                splitnames = place_name.split(', ')\n",
    "\n",
    "                # get the state code part of the string (it's the second part)\n",
    "                state_code = splitnames[1]\n",
    "\n",
    "                # add the state field on tweet_match object\n",
    "                tweet['state'] = state_code\n",
    "\n",
    "                # assign region codes to different states\n",
    "                if state_code == \"WA\" or state_code == \"OR\" or state_code == \"CA\" or state_code == \"ID\" or state_code == \"NV\" or state_code == \"MT\" or state_code == \"WY\" or state_code == \"UT\" or state_code == \"AZ\" or state_code == \"CO\" or state_code == \"NM\" or state_code == \"AK\" or state_code == \"HI\":\n",
    "                    region = \"West\"\n",
    "                elif state_code == \"ND\" or state_code == \"SD\" or state_code == \"NE\" or state_code == \"KS\" or state_code == \"MN\" or state_code == \"IA\" or state_code == \"MO\" or state_code == \"WI\" or state_code == \"IL\" or state_code == \"MI\" or state_code == \"IN\" or state_code == \"OH\":\n",
    "                    region = \"Midwest\"\n",
    "                elif state_code == \"PA\" or state_code == \"NY\" or state_code == \"NJ\" or state_code == \"CT\" or state_code == \"RI\" or state_code == \"MA\" or state_code == \"VT\" or state_code == \"NH\" or state_code == \"ME\":\n",
    "                    region = \"Northeast\"\n",
    "                else: # all the states not listed in the above 'if' or 'elif' conditionals\n",
    "                    region = \"South\"\n",
    "\n",
    "                # add the region to tweet_match object\n",
    "                tweet['region'] = region\n",
    "\n",
    "                # add to new list\n",
    "                all_tweets.append(tweet)\n",
    "    return all_tweets\n",
    "\n",
    "\n",
    "def add_dummy(tweetz):\n",
    "    all_tweets = []\n",
    "    for tweet in tweetz:\n",
    "        region = tweet['region']\n",
    "        # assign region to dummy variables\n",
    "        if region == \"West\":\n",
    "            W = 1\n",
    "        else:\n",
    "            W = 0\n",
    "        # add the West dummy variable to tweet_match object\n",
    "        tweet['W'] = W\n",
    "        \n",
    "        if region == \"Midwest\":\n",
    "            MW = 1\n",
    "        else:\n",
    "            MW = 0\n",
    "        # add the Midwest dummy variable to tweet_match object\n",
    "        tweet['MW'] = MW\n",
    "\n",
    "        if region == \"Northeast\":\n",
    "            NE = 1\n",
    "        else:\n",
    "            NE = 0\n",
    "        # add the Northeast dummy variable to tweet_match object\n",
    "        tweet['NE'] = NE\n",
    "\n",
    "         # add to new list\n",
    "        all_tweets.append(tweet)\n",
    "        \n",
    "    return all_tweets\n",
    "\n",
    "# format data for pandas dataframe\n",
    "def build_dataframe(all_tweets):\n",
    "    input_list = []\n",
    "    for tweet in all_tweets:\n",
    "        tweet_as_list = []\n",
    "        tweet_as_list.append(tweet['author_id'])\n",
    "        tweet_as_list.append(tweet['created_at'])\n",
    "        tweet_as_list.append(tweet['geo']['place_id'])\n",
    "        tweet_as_list.append(tweet['id'])\n",
    "        tweet_as_list.append(tweet['region'])\n",
    "        tweet_as_list.append(tweet['state'])\n",
    "        tweet_as_list.append(tweet['W'])\n",
    "        tweet_as_list.append(tweet['MW'])\n",
    "        tweet_as_list.append(tweet['NE'])\n",
    "        tweet_as_list.append(tweet['text'])\n",
    "        input_list.append(tweet_as_list)\n",
    "\n",
    "    # create new dataframe    \n",
    "    df = pd.DataFrame(input_list, columns=['author_id', 'created_at', 'geo', 'id', 'region', 'state', 'W','MW','NE','text'])\n",
    "    return df\n",
    "\n",
    "# clean the tweets\n",
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)        \n",
    "    return input_txt\n",
    "\n",
    "def clean_tweets(all_tweets):\n",
    "    #remove twitter Return handles (RT @xxx:)\n",
    "    all_tweets = np.vectorize(remove_pattern)(all_tweets, \"RT @[\\w]*:\") \n",
    "    \n",
    "    #remove twitter handles (@xxx)\n",
    "    all_tweets = np.vectorize(remove_pattern)(all_tweets, \"@[\\w]*\")\n",
    "    \n",
    "    #remove URL links (httpxxx)\n",
    "    all_tweets = np.vectorize(remove_pattern)(all_tweets, \"https?://[A-Za-z0-9./]*\")\n",
    "    \n",
    "    #remove special characters, numbers, punctuations (except for #)\n",
    "    all_tweets = np.core.defchararray.replace(all_tweets, \"[^a-zA-Z]\", \" \")\n",
    "    \n",
    "    return all_tweets\n",
    "\n",
    "def score_sentiment(df):\n",
    "    scores = []\n",
    "    # declare variables for scores\n",
    "    compound_list = []\n",
    "    positive_list = []\n",
    "    negative_list = []\n",
    "    neutral_list = []\n",
    "    for i in range(df['text'].shape[0]):\n",
    "    # print(analyser.polarity_scores(sentiments_pd['text'][i]))\n",
    "        compound = analyzer.polarity_scores(df['text'][i])[\"compound\"]\n",
    "        pos = analyzer.polarity_scores(df['text'][i])[\"pos\"]\n",
    "        neu = analyzer.polarity_scores(df['text'][i])[\"neu\"]\n",
    "        neg = analyzer.polarity_scores(df['text'][i])[\"neg\"]\n",
    "\n",
    "        scores.append({\"Compound\": compound,\n",
    "                           \"Positive\": pos,\n",
    "                           \"Negative\": neg,\n",
    "                           \"Neutral\": neu\n",
    "                      })\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "958478b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "Hour 0 : 11 tweets\n",
      "200\n",
      "Hour 1 : 7 tweets\n",
      "200\n",
      "Hour 2 : 6 tweets\n",
      "200\n",
      "Hour 3 : 8 tweets\n",
      "200\n",
      "Hour 4 : 9 tweets\n",
      "200\n",
      "Hour 5 : 5 tweets\n",
      "200\n",
      "Hour 6 : 4 tweets\n",
      "200\n",
      "Hour 7 : 3 tweets\n",
      "200\n",
      "Hour 8 : 2 tweets\n",
      "200\n",
      "Hour 9 : 2 tweets\n",
      "200\n",
      "Hour 10 : 5 tweets\n",
      "200\n",
      "Hour 11 : 3 tweets\n",
      "200\n",
      "Hour 12 : 9 tweets\n",
      "200\n",
      "Hour 13 : 7 tweets\n",
      "200\n",
      "Hour 14 : 12 tweets\n",
      "200\n",
      "Hour 15 : 13 tweets\n",
      "200\n",
      "Hour 16 : 11 tweets\n",
      "200\n",
      "Hour 17 : 6 tweets\n",
      "200\n",
      "Hour 18 : 12 tweets\n",
      "200\n",
      "Hour 19 : 7 tweets\n",
      "200\n",
      "Hour 20 : 10 tweets\n",
      "200\n",
      "Hour 21 : 7 tweets\n",
      "200\n",
      "Hour 22 : 10 tweets\n",
      "200\n",
      "Hour 23 : 8 tweets\n",
      "Total tweets: 177\n",
      "Total places: 92\n",
      "             author_id                created_at               geo  \\\n",
      "0            410850631  2021-05-31T00:31:34.000Z  c3f37afa9efcf94b   \n",
      "1             30585609  2021-05-31T00:29:04.000Z  28db2dbc4240f0b2   \n",
      "2             20536137  2021-05-31T00:20:11.000Z  d1280141e5f979cf   \n",
      "3            626152908  2021-05-31T00:15:12.000Z  e09538b2e39d94df   \n",
      "4             22319823  2021-05-31T00:08:50.000Z  00e9226863a6e5a4   \n",
      "5            171941361  2021-05-31T00:01:37.000Z  00c39537733fa112   \n",
      "6              4925881  2021-05-31T01:47:43.000Z  c3f37afa9efcf94b   \n",
      "7             97077778  2021-05-31T01:41:12.000Z  4894f2226f25db16   \n",
      "8  1026980719778836481  2021-05-31T01:31:59.000Z  c3f37afa9efcf94b   \n",
      "9             19433070  2021-05-31T01:31:46.000Z  8193d87541f11dfb   \n",
      "\n",
      "                    id     region state  W  MW  NE  \\\n",
      "0  1399161598833463301      South    TX  0   0   0   \n",
      "1  1399160966772924418  Northeast    MA  0   0   1   \n",
      "2  1399158733897306114       West    WA  1   0   0   \n",
      "3  1399157477955018752  Northeast    MA  0   0   1   \n",
      "4  1399155874938109961      South    GA  0   0   0   \n",
      "5  1399154059312091137  Northeast    NY  0   0   1   \n",
      "6  1399180760901369865      South    TX  0   0   0   \n",
      "7  1399179119468814341       West    AZ  1   0   0   \n",
      "8  1399176800950001681      South    TX  0   0   0   \n",
      "9  1399176745165725699  Northeast    MA  0   0   1   \n",
      "\n",
      "                                                text  Compound  Positive  \\\n",
      "0  not only am I missing #bitcoin 2021 in Miami b...   -0.5267     0.000   \n",
      "1  Ads for Bitcoin make no sense. Like.... do you...   -0.5122     0.000   \n",
      "2                          Google, Bitcoin, Netflix.    0.0000     0.000   \n",
      "3  I wanna bitcoin but i really don’t think it’s ...    0.3291     0.101   \n",
      "4  I just want to know who the hell is buying Bit...   -0.6800     0.052   \n",
      "5   Do not sell your any #Bitcoin \\n\\nJust #HODL ...    0.0000     0.000   \n",
      "6  If you don’t love it at $25, you do not deserv...    0.6369     0.160   \n",
      "7                            Buy the drop in bitcoin   -0.2732     0.000   \n",
      "8   You tweet more about bitcoin than most bitcoi...    0.0000     0.000   \n",
      "9  Very articulate argument for how one could des...   -0.8393     0.000   \n",
      "\n",
      "   Negative  Neutral  \n",
      "0     0.216    0.784  \n",
      "1     0.264    0.736  \n",
      "2     0.000    1.000  \n",
      "3     0.000    0.899  \n",
      "4     0.194    0.754  \n",
      "5     0.000    1.000  \n",
      "6     0.000    0.840  \n",
      "7     0.344    0.656  \n",
      "8     0.000    1.000  \n",
      "9     0.391    0.609  \n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    headers = create_headers(bearer_token)\n",
    "    \n",
    "    tweetz = []\n",
    "    placeDict = {} # keys = place_id, values = place\n",
    "    for hour in range(0, end_hour+1):\n",
    "        # Build and execute query\n",
    "        query_params = build_params(select_year, select_month, select_day, hour, default_query_params)\n",
    "        json_response = connect_to_endpoint(search_url, headers, default_query_params)\n",
    "        \n",
    "        # Check the result count. If there are no results, don't process the tweets.\n",
    "        result_count = json_response[\"meta\"][\"result_count\"]\n",
    "        print(\"Hour\", hour, \":\", result_count, \"tweets\")\n",
    "        if result_count == 0:\n",
    "            time.sleep(1) # Sleep for 1 second\n",
    "            continue # This skips this run of the for-loop and goes to the next run\n",
    "                \n",
    "        # Add tweets to monthly tweets array\n",
    "        tweetz = tweetz + json_response[\"data\"]\n",
    "        \n",
    "        # Add new places to places dictionary\n",
    "        res_places = json_response[\"includes\"][\"places\"]\n",
    "        for place in res_places:\n",
    "            place_id = place['id']\n",
    "            if place_id not in placeDict: # to avoid overwriting existing places\n",
    "                placeDict[place_id] = place\n",
    "\n",
    "        time.sleep(1) # Sleep for 1 second\n",
    "        \n",
    "    print(\"Total tweets:\", len(tweetz))\n",
    "    print(\"Total places:\", len(placeDict.keys()))\n",
    "    \n",
    "    tweets_with_region = add_region(tweetz, placeDict)\n",
    "    tweet_with_dummies = add_dummy(tweets_with_region)\n",
    "    df_tweetz = build_dataframe(tweet_with_dummies)\n",
    "    \n",
    "    # use clean function on tweet text\n",
    "    cleaned_tweets = clean_tweets(df_tweetz['text'])\n",
    "    df_tweetz['text'] = cleaned_tweets\n",
    "\n",
    "    # score sentiment for dataset\n",
    "    scored_tweets = score_sentiment(df_tweetz)\n",
    "    # initialize another pandas dataframe and combine it with original dataframe\n",
    "    sentiments_score = pd.DataFrame.from_dict(scored_tweets)\n",
    "    df_final = df_tweetz.join(sentiments_score)\n",
    "    result3 = df_final.head(10)\n",
    "    print(result3)\n",
    "    \n",
    "    df_final.to_excel(r'/Users/Linde/Library/Mobile Documents/com~apple~CloudDocs/Documents/Master/ESMT/01_Class/M5/Thesis/Data/Curated_Tweets/' + filename, index = False)\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd6a9d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
